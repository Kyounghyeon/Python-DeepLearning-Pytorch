{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZoTer7yA2Jx"
   },
   "source": [
    "# 0. 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPEzxzWA8vzh",
    "outputId": "26cbe956-0e10-4cd6-91c8-a8db43a1c569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pv8ZWxil9ihv",
    "outputId": "d12fde44-2888-4b54-d8b4-c6966f163c75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/colab\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aMYfSLyR-M0d",
    "outputId": "d52b6fe9-1253-4cc4-caa5-fe40656af41b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/colab'"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VDIQqt0A0Wk"
   },
   "source": [
    "# 1. 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vwrJ3z6W-ttt"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YV1Nu4Ik-1Cy"
   },
   "outputs": [],
   "source": [
    "# 벡터 정의\n",
    "vector1 = torch.tensor([1., 2., 3.])\n",
    "vector2 = torch.tensor([4., 5., 6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwNXc1UM_PAE",
    "outputId": "7e3a5374-7322-4f2e-949c-7eb7dabca1a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.4000, 0.5000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch 내장함수를 이용한 벡터wise 연산\n",
    "torch.add(vector1, vector2) # 같은 위치끼리 더하고\n",
    "torch.sub(vector1, vector2) # 빼고\n",
    "torch.mul(vector1, vector2) # 곱하고\n",
    "torch.div(vector1, vector2) # 나누고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HxB8PLhJ_pDk"
   },
   "outputs": [],
   "source": [
    "# 행렬 정의\n",
    "matrix1 = torch.tensor([[1.,2.], [3.,4.]])\n",
    "matrix2 = torch.tensor([[5.,6.], [7.,8.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-S8p8PyZ_4bs",
    "outputId": "d19de77b-de87-4d11-cbba-aba463a6bd4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 22.],\n",
       "        [43., 50.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(matrix1 , matrix2) # 같은 위치끼리 더하고\n",
    "torch.sub(matrix1 , matrix2) # 빼고\n",
    "torch.mul(matrix1 , matrix2) # 곱하고\n",
    "torch.div(matrix1 , matrix2) # 나누고\n",
    "torch.matmul(matrix1, matrix2) # 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtjx1cs_AKOX",
    "outputId": "33c980eb-eafd-4786-f989-ec630aa249fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 정의\n",
    "tensor1 = torch.tensor([ [[1.,2.], [3.,4.]],\n",
    "                         [[5.,6.], [7.,8.]] ])\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPzl3zR-P0jv",
    "outputId": "582b45a0-93c5-462c-cd1a-e13907c2e823"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  7.,  10.],\n",
       "         [ 15.,  22.]],\n",
       "\n",
       "        [[ 67.,  78.],\n",
       "         [ 91., 106.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서 연산\n",
    "torch.matmul(tensor1, tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VquRAUrAhYH"
   },
   "source": [
    "# 2. Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj76R0FEA8D6"
   },
   "source": [
    "Back propagation(역전파)를 이용해서 파라미터를 업데이트할 때 Autograd 방식으로 쉽게 구현할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qOkEDTiQBHP_"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "  DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6knuspiBcKA"
   },
   "source": [
    "`batch_size` : 딥러닝 모델에서 파라미터를 업데이트할 때 계산되는 데이터의 개수  \n",
    "`input_size` : 입력층의 노드 수  \n",
    "- `input_size`의 크기를 가지는 데이터를 `batch_size`만큼 사용  (아래 예제에서는 (64, 1000))  \n",
    "`hidden_size` : 은닉층의 노드 수   \n",
    "`output_size` : 출력되는 벡터 크기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QMIeNHOdBR8p"
   },
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "input_size = 1000\n",
    "hidden_size = 100\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZWS70TV0Ch8o"
   },
   "outputs": [],
   "source": [
    "# sample data 생성\n",
    "# 입력층\n",
    "x = torch.randn(batch_size,\n",
    "                input_size,\n",
    "                device = DEVICE,\n",
    "                dtype = torch.float,\n",
    "                requires_grad = False)\n",
    "\n",
    "# 은닉층1, 역전파를 통해 업데이트 해야 하는 대상\n",
    "w1 = torch.randn(input_size,\n",
    "                hidden_size,\n",
    "                device = DEVICE,\n",
    "                dtype = torch.float,\n",
    "                requires_grad = True)\n",
    "\n",
    "# 은닉층2, 역전파를 통해 업데이트 해야 하는 대상\n",
    "w2 = torch.randn(hidden_size,\n",
    "                output_size,\n",
    "                device = DEVICE,\n",
    "                dtype = torch.float,\n",
    "                requires_grad = True)\n",
    "\n",
    "# 출력층\n",
    "y = torch.randn(batch_size,\n",
    "                output_size,\n",
    "                device = DEVICE,\n",
    "                dtype = torch.float,\n",
    "                requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 100])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Htwnj3XrEDol",
    "outputId": "dc04353e-0f21-4a08-c9cb-003cfd3c6159",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100 \t Loss: 1038.6949462890625\n",
      "Iteration: 200 \t Loss: 8.037734985351562\n",
      "Iteration: 300 \t Loss: 0.10370723903179169\n",
      "Iteration: 400 \t Loss: 0.0019828418735414743\n",
      "Iteration: 500 \t Loss: 0.00016050023259595037\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-6 # learning rate\n",
    "for t in range(1, 501): # epoch = 500\n",
    "  y_pred = x.mm(w1).clamp(min = 0).mm(w2) # 예측값 = x와 w1 행렬곱 -> clamp(min=0 이므로, ReLU와 같은 활성화 함수)적용 -> w2 행렬곱 \n",
    "  \n",
    "  loss = (y_pred-y).pow(2).sum() # SSE\n",
    "  if t % 100 == 0:\n",
    "    print(f\"Iteration: {t} \\t Loss: {loss.item()}\")\n",
    "  loss.backward() # 각 파라미터 값에 대해 gradient를 계산 후 역전파 진행\n",
    "\n",
    "  with torch.no_grad(): \n",
    "    # gradient 업데이트 \n",
    "    w1 -= lr * w1.grad \n",
    "    w2 -= lr * w2.grad\n",
    "    \n",
    "    # gradient 초기화\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loss.backward()` 이전까지  \n",
    "- 2개의 hidden layer를 한번 거쳐 손실함수를 계산하는 과정  \n",
    "\n",
    "`loss.backward()`  \n",
    "- `requires_grad = True`인 텐서에 대해 그래디언트값을 계산 ($ dLoss/dw $) \n",
    "- `w1.grad`, `w2.grad`로 호출 가능해짐  \n",
    "\n",
    "`with torch.no_grad():`   \n",
    "- 텐서를 정의할 때 gradient 연산 옵션을 끌 때, requires_grad = False로 만들어줌\n",
    "- 메모리 사용량을 아낌\n",
    "- 각 파라미터 값에 대해 그래디언트를 계산한 결과를 이용해 파라미터 값을 업데이트 할때, 해당 시점의 그래디언트 값을 고정한다는 의미\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU2MdVM6FHwS"
   },
   "source": [
    "## clamp 함수 설명\n",
    "위 예시에서는 min = 0 이고, max는 없기 때문에, ReLU 함수와 똑같다.\n",
    "\n",
    "\\begin{cases}\n",
    "min,\\;if\\;x<min\\\\\n",
    "x,\\;if\\;min\\leq x\\leq\\max\\\\\n",
    "max, \\; if\\; x > max\n",
    "\\end{cases}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPh9rqaSIGUB"
   },
   "source": [
    "# 추가로 공부해볼 것들\n",
    "1. Back Propagation (역전파)\n",
    "2. Gradient Descent Method"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Chap01 - Autograd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
