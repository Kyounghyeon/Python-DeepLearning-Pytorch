{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1MxJp0kk13G"
   },
   "source": [
    "# Create multi layer perceptron model with MNIST data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCOjnGYGk4PR",
    "outputId": "36df9c9d-15de-44a8-c4a2-c9771b68af2b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-91874b305a32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tlfRNvBlYPk",
    "outputId": "39a2aefb-a62f-4ba9-9e3c-d19d102d0779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] 지정된 경로를 찾을 수 없습니다: '/content/drive/MyDrive/colab/'\n",
      "C:\\Users\\whoe9\\Desktop\\jupyternotebook\\Pytorch\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/colab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X9ldR2YnJiw"
   },
   "source": [
    "## 1. Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pmtadBZDk13I"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn # neural network를 만들 때 필요한 함수를 모아놓은 모듈\n",
    "import torch.nn.functional as F # torch.nn 중에서도 자주 사용되는 함수\n",
    "from torchvision import transforms, datasets # CV분야에서 자주 사용되는 torchvision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySQX7tH_nS5H"
   },
   "source": [
    "## 2. Check version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M-mfABYWk13I"
   },
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hc1HTWz5mAhW",
    "outputId": "f8d68704-bfcc-413a-9ec9-583ea6f1aff7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9ISRUeSQmB-G",
    "outputId": "7ef011a6-26e3-4cfc-edae-47ee8a5b723d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "NQjqtFLEmIXW"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\whoe9\\\\Desktop\\\\jupyternotebook\\\\Pytorch'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfWpQTOYnYDz"
   },
   "source": [
    "## 3. MNIST 데이터 다운로드(train, test 분리)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMLNREE7n2S7"
   },
   "source": [
    "`datasets.MNIST`를 이용해서 데이터를 불러올 수 있고, 이미지 형태이기 때문에 `transforms.ToTensor` 옵션을 사용해 텐서형태로 불러옴. 다만 MLP 모델은 input data의 값이 커질수록 불안정해지므로 정규화를 0\\~255 사이의 텐서값을 0~1 범위로 정규화하여 불러움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sxmOmLBvmbv9"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
    "                               train = True,\n",
    "                               download = True,\n",
    "                               transform = transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
    "                               train = False,\n",
    "                               download = True,\n",
    "                               transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../data/MNIST\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnI00di9n159"
   },
   "source": [
    "위에서 다운로드한 MNIST 데이터셋을 미니 배치 단위로 분리해서 지정. 이미지 데이터를 배치 사이즈 단위로 미니 배치를 구성하게 됨.  \n",
    "즉, 미니 배치 1개 = 배치 사이즈 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-9G1naSPn1bY"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**미니 배치**  \n",
    "총 60,000개의 손글씨 사진들을 전부 비교하기에는 시공간적으로 효율적이지 못함.  \n",
    "때문에 미니배치라는 전체 데이터의 일부만을 학습에 이용하는 방법.    \n",
    "- 1 epoch : 32개 학습 -> 가중치 업데이트 -> 그다음 32개 학습 -> ... -> 총 60,000/32  = 1,875번 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrabRMfPnotd"
   },
   "source": [
    "## 4. 데이터 확인하기 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiWbyLyZpOGW",
    "outputId": "aae0dd72-2a4f-4dd7-d78e-91aee8093ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([32, 1, 28, 28]) type:  torch.FloatTensor\n",
      "y_train:  torch.Size([32]) type:  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train: ', X_train.size(), 'type: ', X_train.type())\n",
    "    print('y_train: ', y_train.size(), 'type: ', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExfymiCFqOxm"
   },
   "source": [
    "출력 결과 해석  \n",
    "- 32개의 이미지 데이터가 1개의 미니 배치를 구성\n",
    "- 가로 28, 세로 28 픽셀\n",
    "- 채널 1 -> Gray Scale (흑백)\n",
    "- type 도 추가로 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDyZgDjkqjMN"
   },
   "source": [
    "## 5. 데이터 확인하기 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "id": "Y_YZtm_CqkcL",
    "outputId": "e6a37e26-debb-49b1-fae8-d2b662e90ce2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize = 1\n",
    "plt.figure(figsize = (10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28,28), cmap = \"gray_r\")\n",
    "    plt.title(\"Class: \" + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWmNPhkJqphX"
   },
   "source": [
    "## 6. MLP 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `nn.Linear` : affine 변환을 담당하는 layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xG-_C-ecsRuE"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module): # nn.Module method 상속 -> nn.Module 내의 함수를 Net class 안에서 이용가능함\n",
    "    \n",
    "    # 초기화\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(28 * 28, 512) # 처음 input layer의 노드수 = 가로*세로*채널수 \n",
    "        self.fc2 = nn.Linear(512, 256) \n",
    "        self.fc3 = nn.Linear(256, 10) # Output : 0~9까지의 이미지 label -> 10개 // Loss를 계산하기 위해서 개수 똑같이 맞춰야 함\n",
    "    \n",
    "    # 순전파\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # MLP 모델은 1차원 데이터를 입력 받음. 기존 데이터는 (28, 28)의 2차원 데이터이므로 view를 이용하여 28*28개의 1차원 데이터로 변환\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x\n",
    "\n",
    "model = Net().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**파라미터 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 784])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([10, 256])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([10])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}')\n",
    "    print(f'param.requries_grad:{param.requires_grad}')\n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JsKmoMdvPeE"
   },
   "source": [
    "## 7. 옵티마이저, 손실함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "o8M4mR6lwA98"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5) # stochastic gradient descent \n",
    "criterion = nn.CrossEntropyLoss() # 손실함수 : CrossEntropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5DmilMfwgE5"
   },
   "source": [
    "[Cross Entropy Loss function](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tvv0VWevaDj"
   },
   "source": [
    "## 8. train 데이터에 대한 모델 성능 확인하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "uGwHInvAwkvk"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train() # 정의한 모델을 학습 상태로 지정\n",
    "    for batch_idx,(image, label) in enumerate(train_loader): \n",
    "        image = image.to(DEVICE) # 사용할 이미지(인풋)와 레이블을 GPU 또는 CPU에 할당\n",
    "        label = label.to(DEVICE) # true y값\n",
    "        optimizer.zero_grad() # 그래디언트 초기화\n",
    "        output = model(image) # prediction 값, train_loader부터 입력된 이미지 데이터를 input에 넣어 MLP 모델을 돌리고 결과를 output에 저장\n",
    "        loss = criterion(output, label) # Loss 함수로 평가\n",
    "        loss.backward() # loss함수를 최소화하도록 계산된 그래디언트로 역전파\n",
    "        optimizer.step() # 파라미터 값 업데이트, 다음 에포크 실행\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch {} [ {}/{} ({:.0f}%) ] /t Train Loss: {:.6f}\".format(ep, \n",
    "                                                                                batch_idx * len(image),\n",
    "                                                                                len(train_loader.dataset), \n",
    "                                                                                100. * batch_idx / len(train_loader),\n",
    "                                                                                loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. test 데이터에 대한 모델 성능 확인하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval() # 평가 모드\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1] #output은 크기가 10이며, input에 대한 각각 label의 예측 확률값 벡터값임. 확률이 가장 높은(max) label로 분류하는 것임.\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item() # 실제와 예측값이 맞으면 correct에 +1\n",
    "\n",
    "    test_loss /= len(test_loader.dataset) # 전체 loss를 미니배치 총 개수만큼 나눔 (1875개)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1 [ 0/60000 0%) ] /t Train Loss: 2.373925\n",
      "Train Epoch 1 [ 6400/60000 11%) ] /t Train Loss: 2.279435\n",
      "Train Epoch 1 [ 12800/60000 21%) ] /t Train Loss: 2.307403\n",
      "Train Epoch 1 [ 19200/60000 32%) ] /t Train Loss: 2.303364\n",
      "Train Epoch 1 [ 25600/60000 43%) ] /t Train Loss: 2.317318\n",
      "Train Epoch 1 [ 32000/60000 53%) ] /t Train Loss: 2.295982\n",
      "Train Epoch 1 [ 38400/60000 64%) ] /t Train Loss: 2.268548\n",
      "Train Epoch 1 [ 44800/60000 75%) ] /t Train Loss: 2.309198\n",
      "Train Epoch 1 [ 51200/60000 85%) ] /t Train Loss: 2.283495\n",
      "Train Epoch 1 [ 57600/60000 96%) ] /t Train Loss: 2.284096\n",
      "\\[EPOCH: 1], \t Test Loss : 0.0694, \t Test Accuracy : 27.04 \n",
      "\n",
      "Train Epoch 2 [ 0/60000 0%) ] /t Train Loss: 2.228342\n",
      "Train Epoch 2 [ 6400/60000 11%) ] /t Train Loss: 2.207078\n",
      "Train Epoch 2 [ 12800/60000 21%) ] /t Train Loss: 2.155443\n",
      "Train Epoch 2 [ 19200/60000 32%) ] /t Train Loss: 2.083037\n",
      "Train Epoch 2 [ 25600/60000 43%) ] /t Train Loss: 1.994179\n",
      "Train Epoch 2 [ 32000/60000 53%) ] /t Train Loss: 1.631279\n",
      "Train Epoch 2 [ 38400/60000 64%) ] /t Train Loss: 1.595850\n",
      "Train Epoch 2 [ 44800/60000 75%) ] /t Train Loss: 1.611427\n",
      "Train Epoch 2 [ 51200/60000 85%) ] /t Train Loss: 1.262537\n",
      "Train Epoch 2 [ 57600/60000 96%) ] /t Train Loss: 1.329333\n",
      "\\[EPOCH: 2], \t Test Loss : 0.0368, \t Test Accuracy : 67.02 \n",
      "\n",
      "Train Epoch 3 [ 0/60000 0%) ] /t Train Loss: 1.182994\n",
      "Train Epoch 3 [ 6400/60000 11%) ] /t Train Loss: 1.041083\n",
      "Train Epoch 3 [ 12800/60000 21%) ] /t Train Loss: 0.999324\n",
      "Train Epoch 3 [ 19200/60000 32%) ] /t Train Loss: 0.750766\n",
      "Train Epoch 3 [ 25600/60000 43%) ] /t Train Loss: 1.359892\n",
      "Train Epoch 3 [ 32000/60000 53%) ] /t Train Loss: 1.155713\n",
      "Train Epoch 3 [ 38400/60000 64%) ] /t Train Loss: 0.878035\n",
      "Train Epoch 3 [ 44800/60000 75%) ] /t Train Loss: 0.798421\n",
      "Train Epoch 3 [ 51200/60000 85%) ] /t Train Loss: 0.624438\n",
      "Train Epoch 3 [ 57600/60000 96%) ] /t Train Loss: 0.622796\n",
      "\\[EPOCH: 3], \t Test Loss : 0.0228, \t Test Accuracy : 78.71 \n",
      "\n",
      "Train Epoch 4 [ 0/60000 0%) ] /t Train Loss: 0.586804\n",
      "Train Epoch 4 [ 6400/60000 11%) ] /t Train Loss: 0.573097\n",
      "Train Epoch 4 [ 12800/60000 21%) ] /t Train Loss: 0.700400\n",
      "Train Epoch 4 [ 19200/60000 32%) ] /t Train Loss: 0.642767\n",
      "Train Epoch 4 [ 25600/60000 43%) ] /t Train Loss: 0.822941\n",
      "Train Epoch 4 [ 32000/60000 53%) ] /t Train Loss: 0.702547\n",
      "Train Epoch 4 [ 38400/60000 64%) ] /t Train Loss: 0.437279\n",
      "Train Epoch 4 [ 44800/60000 75%) ] /t Train Loss: 0.493712\n",
      "Train Epoch 4 [ 51200/60000 85%) ] /t Train Loss: 0.728538\n",
      "Train Epoch 4 [ 57600/60000 96%) ] /t Train Loss: 0.411890\n",
      "\\[EPOCH: 4], \t Test Loss : 0.0172, \t Test Accuracy : 84.04 \n",
      "\n",
      "Train Epoch 5 [ 0/60000 0%) ] /t Train Loss: 0.598163\n",
      "Train Epoch 5 [ 6400/60000 11%) ] /t Train Loss: 0.684422\n",
      "Train Epoch 5 [ 12800/60000 21%) ] /t Train Loss: 0.438852\n",
      "Train Epoch 5 [ 19200/60000 32%) ] /t Train Loss: 1.048084\n",
      "Train Epoch 5 [ 25600/60000 43%) ] /t Train Loss: 0.539835\n",
      "Train Epoch 5 [ 32000/60000 53%) ] /t Train Loss: 0.373891\n",
      "Train Epoch 5 [ 38400/60000 64%) ] /t Train Loss: 0.309591\n",
      "Train Epoch 5 [ 44800/60000 75%) ] /t Train Loss: 0.507809\n",
      "Train Epoch 5 [ 51200/60000 85%) ] /t Train Loss: 0.303976\n",
      "Train Epoch 5 [ 57600/60000 96%) ] /t Train Loss: 0.585328\n",
      "\\[EPOCH: 5], \t Test Loss : 0.0142, \t Test Accuracy : 86.80 \n",
      "\n",
      "Train Epoch 6 [ 0/60000 0%) ] /t Train Loss: 0.567733\n",
      "Train Epoch 6 [ 6400/60000 11%) ] /t Train Loss: 0.468021\n",
      "Train Epoch 6 [ 12800/60000 21%) ] /t Train Loss: 0.544147\n",
      "Train Epoch 6 [ 19200/60000 32%) ] /t Train Loss: 0.430469\n",
      "Train Epoch 6 [ 25600/60000 43%) ] /t Train Loss: 0.410655\n",
      "Train Epoch 6 [ 32000/60000 53%) ] /t Train Loss: 0.402412\n",
      "Train Epoch 6 [ 38400/60000 64%) ] /t Train Loss: 0.408702\n",
      "Train Epoch 6 [ 44800/60000 75%) ] /t Train Loss: 0.368963\n",
      "Train Epoch 6 [ 51200/60000 85%) ] /t Train Loss: 0.421946\n",
      "Train Epoch 6 [ 57600/60000 96%) ] /t Train Loss: 0.384964\n",
      "\\[EPOCH: 6], \t Test Loss : 0.0128, \t Test Accuracy : 88.06 \n",
      "\n",
      "Train Epoch 7 [ 0/60000 0%) ] /t Train Loss: 0.638735\n",
      "Train Epoch 7 [ 6400/60000 11%) ] /t Train Loss: 0.349665\n",
      "Train Epoch 7 [ 12800/60000 21%) ] /t Train Loss: 0.383224\n",
      "Train Epoch 7 [ 19200/60000 32%) ] /t Train Loss: 0.322150\n",
      "Train Epoch 7 [ 25600/60000 43%) ] /t Train Loss: 0.531353\n",
      "Train Epoch 7 [ 32000/60000 53%) ] /t Train Loss: 0.243531\n",
      "Train Epoch 7 [ 38400/60000 64%) ] /t Train Loss: 0.364732\n",
      "Train Epoch 7 [ 44800/60000 75%) ] /t Train Loss: 0.196862\n",
      "Train Epoch 7 [ 51200/60000 85%) ] /t Train Loss: 0.333630\n",
      "Train Epoch 7 [ 57600/60000 96%) ] /t Train Loss: 0.596407\n",
      "\\[EPOCH: 7], \t Test Loss : 0.0119, \t Test Accuracy : 88.80 \n",
      "\n",
      "Train Epoch 8 [ 0/60000 0%) ] /t Train Loss: 0.338404\n",
      "Train Epoch 8 [ 6400/60000 11%) ] /t Train Loss: 0.309574\n",
      "Train Epoch 8 [ 12800/60000 21%) ] /t Train Loss: 0.368056\n",
      "Train Epoch 8 [ 19200/60000 32%) ] /t Train Loss: 0.223339\n",
      "Train Epoch 8 [ 25600/60000 43%) ] /t Train Loss: 0.463949\n",
      "Train Epoch 8 [ 32000/60000 53%) ] /t Train Loss: 0.231496\n",
      "Train Epoch 8 [ 38400/60000 64%) ] /t Train Loss: 0.145519\n",
      "Train Epoch 8 [ 44800/60000 75%) ] /t Train Loss: 0.493626\n",
      "Train Epoch 8 [ 51200/60000 85%) ] /t Train Loss: 0.421755\n",
      "Train Epoch 8 [ 57600/60000 96%) ] /t Train Loss: 0.346790\n",
      "\\[EPOCH: 8], \t Test Loss : 0.0112, \t Test Accuracy : 89.49 \n",
      "\n",
      "Train Epoch 9 [ 0/60000 0%) ] /t Train Loss: 0.398730\n",
      "Train Epoch 9 [ 6400/60000 11%) ] /t Train Loss: 0.435566\n",
      "Train Epoch 9 [ 12800/60000 21%) ] /t Train Loss: 0.397346\n",
      "Train Epoch 9 [ 19200/60000 32%) ] /t Train Loss: 0.553802\n",
      "Train Epoch 9 [ 25600/60000 43%) ] /t Train Loss: 0.239503\n",
      "Train Epoch 9 [ 32000/60000 53%) ] /t Train Loss: 0.406976\n",
      "Train Epoch 9 [ 38400/60000 64%) ] /t Train Loss: 0.311532\n",
      "Train Epoch 9 [ 44800/60000 75%) ] /t Train Loss: 0.728462\n",
      "Train Epoch 9 [ 51200/60000 85%) ] /t Train Loss: 0.273811\n",
      "Train Epoch 9 [ 57600/60000 96%) ] /t Train Loss: 0.548774\n",
      "\\[EPOCH: 9], \t Test Loss : 0.0109, \t Test Accuracy : 89.79 \n",
      "\n",
      "Train Epoch 10 [ 0/60000 0%) ] /t Train Loss: 0.234922\n",
      "Train Epoch 10 [ 6400/60000 11%) ] /t Train Loss: 0.909999\n",
      "Train Epoch 10 [ 12800/60000 21%) ] /t Train Loss: 0.438577\n",
      "Train Epoch 10 [ 19200/60000 32%) ] /t Train Loss: 0.358725\n",
      "Train Epoch 10 [ 25600/60000 43%) ] /t Train Loss: 0.184231\n",
      "Train Epoch 10 [ 32000/60000 53%) ] /t Train Loss: 0.502998\n",
      "Train Epoch 10 [ 38400/60000 64%) ] /t Train Loss: 0.565983\n",
      "Train Epoch 10 [ 44800/60000 75%) ] /t Train Loss: 0.291471\n",
      "Train Epoch 10 [ 51200/60000 85%) ] /t Train Loss: 0.128381\n",
      "Train Epoch 10 [ 57600/60000 96%) ] /t Train Loss: 0.508906\n",
      "\\[EPOCH: 10], \t Test Loss : 0.0104, \t Test Accuracy : 90.38 \n",
      "\n",
      "0:01:53.887734\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "for ep in range(1, epoch+1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200) \n",
    "    #위에서 train 함수를 통해 설정된 파라미터로 test셋에 적합하여 loss와 accuracy 계산\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader) \n",
    "    \n",
    "    \"\"\"train의 결과를 따로 저장하지 않고도 아래에서 바로 평가하는 것을 볼 때,\n",
    "    model.train()을 통해 학습모델에서 추정된 파라미터를 고정하고,\n",
    "    별도로 할당하는 것 없이 model.test()에 이용하는 듯\"\"\"\n",
    "    \n",
    "    print(f\"\\[EPOCH: {ep}], \\t Test Loss : {test_loss:.4f}, \\t Test Accuracy : {test_accuracy:.2f} \\n\")\n",
    "\n",
    "end = dt.datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**결과**\n",
    "- CPU 사용\n",
    "- 모델 총 소요시간 : 약 1분 54초\n",
    "- test accuracy : 90.38 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배운 것\n",
    "- 신경망 모형을 직접 돌려보고 학습시킨 것은 이번이 처음이라 처음부터 끝까지가 새로운 것이었음.\n",
    "- 역전파 과정을 깊게 생각하지 않고 직관적으로 생각하기 위해 노력함.\n",
    "- 전반적인 모델링 과정은 다른 모형들과 비슷하지만, 이미지 데이터를 학습시켰기에 세부적인 것들이 달랐음.\n",
    "- 이미지 데이터라 데이터 하나하나의 feature가 채널, x, y로 구성되었으며,\n",
    "- 미니배치와 SGD를 이용한 학습을 배웠음.\n",
    "- 인풋과 아웃풋의 정의를 확실히 하고, 배치 사이즈, 옵티마이저, 손실함수의 개념을 확실히 짚고 넘어갈 필요성을 느낌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
